{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kuds/rl-drone/blob/main/%5BDrone%20Hover%5D%20Soft%20Actor-Critic%20(SAC).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mujoco\n",
        "\n",
        "# Set up GPU rendering.\n",
        "from google.colab import files\n",
        "import distutils.util\n",
        "import os\n",
        "import subprocess\n",
        "if subprocess.run('nvidia-smi').returncode:\n",
        "  raise RuntimeError(\n",
        "      'Cannot communicate with GPU. '\n",
        "      'Make sure you are using a GPU Colab runtime. '\n",
        "      'Go to the Runtime menu and select Choose runtime type.')\n",
        "\n",
        "# Add an ICD config so that glvnd can pick up the Nvidia EGL driver.\n",
        "# This is usually installed as part of an Nvidia driver package, but the Colab\n",
        "# kernel doesn't install its driver via APT, and as a result the ICD is missing.\n",
        "# (https://github.com/NVIDIA/libglvnd/blob/master/src/EGL/icd_enumeration.md)\n",
        "NVIDIA_ICD_CONFIG_PATH = '/usr/share/glvnd/egl_vendor.d/10_nvidia.json'\n",
        "if not os.path.exists(NVIDIA_ICD_CONFIG_PATH):\n",
        "  with open(NVIDIA_ICD_CONFIG_PATH, 'w') as f:\n",
        "    f.write(\"\"\"{\n",
        "    \"file_format_version\" : \"1.0.0\",\n",
        "    \"ICD\" : {\n",
        "        \"library_path\" : \"libEGL_nvidia.so.0\"\n",
        "    }\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "# Configure MuJoCo to use the EGL rendering backend (requires GPU)\n",
        "print('Setting environment variable to use GPU rendering:')\n",
        "%env MUJOCO_GL=egl\n",
        "\n",
        "# Check if installation was succesful.\n",
        "try:\n",
        "  print('Checking that the installation succeeded:')\n",
        "  import mujoco\n",
        "  mujoco.MjModel.from_xml_string('<mujoco/>')\n",
        "except Exception as e:\n",
        "  raise e from RuntimeError(\n",
        "      'Something went wrong during installation. Check the shell output above '\n",
        "      'for more information.\\n'\n",
        "      'If using a hosted Colab runtime, make sure you enable GPU acceleration '\n",
        "      'by going to the Runtime menu and selecting \"Choose runtime type\".')\n",
        "\n",
        "print('Installation successful.')\n",
        "\n",
        "# Other imports and helper functions\n",
        "import time\n",
        "import itertools\n",
        "import numpy as np\n",
        "\n",
        "# Graphics and plotting.\n",
        "print('Installing mediapy:')\n",
        "!command -v ffmpeg >/dev/null || (apt update && apt install -y ffmpeg)\n",
        "!pip install -q mediapy\n",
        "import mediapy as media\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# More legible printing from numpy.\n",
        "np.set_printoptions(precision=3, suppress=True, linewidth=100)\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "xEQdrmJjK8KR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install robot_descriptions\n",
        "!pip install gymnasium\n",
        "!pip install stable-baselines3"
      ],
      "metadata": {
        "id": "iUb7FllfjNEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium\n",
        "import mujoco\n",
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.vec_env import VecVideoRecorder\n",
        "from stable_baselines3.common.env_util import make_atari_env\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "from stable_baselines3.common.callbacks import CallbackList\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback\n",
        "from stable_baselines3.common.vec_env import VecNormalize\n",
        "import numpy\n",
        "import os\n",
        "import csv\n",
        "import torch\n",
        "import pandas\n",
        "import platform\n",
        "from importlib.metadata import version\n",
        "import matplotlib\n",
        "import matplotlib.pyplot\n",
        "from gymnasium import utils\n",
        "from gymnasium.envs.mujoco import MujocoEnv\n",
        "from gymnasium.spaces import Box\n",
        "import robot_descriptions\n",
        "from robot_descriptions import cf2_mj_description"
      ],
      "metadata": {
        "id": "ccI4U8S-149L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Python Version: {platform.python_version()}\")\n",
        "print(f\"Torch Version: {version('torch')}\")\n",
        "print(f\"Is Cuda Available: {torch.cuda.is_available()}\")\n",
        "print(f\"Cuda Version: {torch.version.cuda}\")\n",
        "print(f\"Gymnasium Version: {version('gymnasium')}\")\n",
        "print(f\"Robot Description Version: {version('robot_descriptions')}\")\n",
        "print(f\"Numpy Version: {version('numpy')}\")\n",
        "print(f\"Mujoco Version: {version('mujoco')}\")\n",
        "print(f\"Stable-Baselines3 Version: {version('stable-baselines3')}\")\n",
        "print(f\"Matplotlib Version: {version('matplotlib')}\")"
      ],
      "metadata": {
        "id": "x6AjavnkLBvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rl_type = \"SAC\"\n",
        "env_str = \"BitCrazy\"\n",
        "log_dir = \"./logs/{}\".format(env_str)\n",
        "name_prefix = \"bit_crazy\""
      ],
      "metadata": {
        "id": "o5FbCArtLRgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparams = {\n",
        "    \"env_str\": env_str,\n",
        "    \"rl_type\": rl_type,\n",
        "    \"eval_freq\": 25_000,\n",
        "    \"n_envs\": 4,\n",
        "    \"total_timesteps\": 1_500_000,\n",
        "    \"log_dir\": log_dir,\n",
        "    \"episode_length\": 1_000\n",
        "}"
      ],
      "metadata": {
        "id": "on1tSGfFLhQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_header = [\"drone_pos_x\",\n",
        "              \"drone_pos_y\",\n",
        "              \"drone_pos_z\",\n",
        "              \"reward\",\n",
        "              \"total_reward\",\n",
        "              \"touch_reported\",\n",
        "              \"sensor_reading\",\n",
        "              \"distance_to_target\",\n",
        "              \"done\"]"
      ],
      "metadata": {
        "id": "NuWDubq6LdYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VideoRecordCallback(BaseCallback):\n",
        "    def __init__(\n",
        "        self,\n",
        "        save_path: str,\n",
        "        video_length: int,\n",
        "        save_freq: int = 5_000,\n",
        "        name_prefix: str =\"rl_model\",\n",
        "        verbose: int = 0):\n",
        "\n",
        "        super().__init__(verbose)\n",
        "        self.save_freq = save_freq\n",
        "        self.video_length = video_length\n",
        "        self.save_path = save_path\n",
        "        self.name_prefix = name_prefix\n",
        "        # Those variables will be accessible in the callback\n",
        "        # (they are defined in the base class)\n",
        "        # The RL model\n",
        "        # self.model = None  # type: BaseAlgorithm\n",
        "        # An alias for self.model.get_env(), the environment used for training\n",
        "        # self.training_env # type: VecEnv\n",
        "        # Number of time the callback was called\n",
        "        # self.n_calls = 0  # type: int\n",
        "        # num_timesteps = n_envs * n times env.step() was called\n",
        "        # self.num_timesteps = 0  # type: int\n",
        "        # local and global variables\n",
        "        # self.locals = {}  # type: Dict[str, Any]\n",
        "        # self.globals = {}  # type: Dict[str, Any]\n",
        "        # The logger object, used to report things in the terminal\n",
        "        # self.logger # type: stable_baselines3.common.logger.Logger\n",
        "        # Sometimes, for event callback, it is useful\n",
        "        # to have access to the parent object\n",
        "        # self.parent = None  # type: Optional[BaseCallback]\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.n_calls % self.save_freq == 0:\n",
        "\n",
        "          name_prefix = f\"{self.name_prefix}_{self.num_timesteps}\"\n",
        "\n",
        "          # Record video of the best model playing\n",
        "          rec_val = make_vec_env(make_env, n_envs=1)\n",
        "          rec_val = VecVideoRecorder(rec_val,\n",
        "                                    self.save_path,\n",
        "                                    video_length=self.video_length,\n",
        "                                    record_video_trigger=lambda x: x == 0,\n",
        "                                    name_prefix=name_prefix)\n",
        "\n",
        "          obs = rec_val.reset()\n",
        "          session_length = 0\n",
        "          total_reward = 0.0\n",
        "          csv_file_name = os.path.join(self.save_path, f\"{name_prefix}.csv\")\n",
        "          with open(csv_file_name, 'w') as csvfile:\n",
        "            csv_writer = csv.writer(csvfile, delimiter=',')\n",
        "            csv_writer.writerow(csv_header)\n",
        "            for _ in range(self.video_length):\n",
        "              session_length += 1\n",
        "              action, _states = self.model.predict(obs)\n",
        "              obs, rewards, dones, info = rec_val.step(action)\n",
        "              total_reward += rewards\n",
        "              #print(obs)\n",
        "              row_data = numpy.concatenate([[obs[0][0],\n",
        "                                             obs[0][1],\n",
        "                                             obs[0][2],\n",
        "                                             rewards[0],\n",
        "                                             total_reward[0],\n",
        "                                             info[0][\"touch_reported\"],\n",
        "                                             info[0][\"sensor_reading\"],\n",
        "                                             info[0][\"distance_to_target\"],\n",
        "                                             dones[0]]])\n",
        "              row_data = numpy.round(row_data, decimals=4)\n",
        "              csv_writer.writerow(row_data)\n",
        "              rec_val.render()\n",
        "\n",
        "              if dones:\n",
        "                break\n",
        "\n",
        "          print(f\"Step: {self.num_timesteps} | Session Length: {session_length} | Total Reward: {int(total_reward[0])}\")\n",
        "\n",
        "          rec_val.close()\n",
        "        return True\n"
      ],
      "metadata": {
        "id": "BqTBA3xCLbCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# --- Configuration ---\n",
        "# The script will modify this file directly\n",
        "filename = cf2_mj_description.MJCF_PATH\n",
        "\n",
        "# 1. Parse the existing XML file\n",
        "try:\n",
        "    tree = ET.parse(filename)\n",
        "    root = tree.getroot()\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{filename}' was not found.\")\n",
        "    exit()\n",
        "except ET.ParseError:\n",
        "    print(f\"Error: The file '{filename}' is not a valid XML file.\")\n",
        "    exit()\n",
        "\n",
        "# 2. Find both the <worldbody> and <sensor> parent nodes\n",
        "worldbody_node = root.find('worldbody')\n",
        "sensor_node = root.find('sensor')\n",
        "\n",
        "# 3. Validate that both parent nodes were found\n",
        "if worldbody_node is not None and sensor_node is not None:\n",
        "    changes_made = False\n",
        "    print(\"Found <worldbody> and <sensor> nodes. Checking for elements...\")\n",
        "\n",
        "    # --- Action 1: Check for and add the fly_zone ---\n",
        "    # The XPath \"./body[@name='fly_zone']\" finds a body element with a specific name\n",
        "    if worldbody_node.find(\"./site[@name='fly_sensor']\") is None:\n",
        "        print(\" -> Body 'fly_zone' not found. Adding it...\")\n",
        "        site_attributes = {\n",
        "            'name': 'fly_sensor',\n",
        "            'pos': '0 0 1',\n",
        "            'size': '0.2',\n",
        "            'type': 'sphere',\n",
        "            'rgba': '0 1 0 .25'\n",
        "        }\n",
        "        # ET.SubElement(ET.Element('site', attrib=site_attributes))\n",
        "        ET.SubElement(worldbody_node, 'site', attrib=site_attributes)\n",
        "        changes_made = True\n",
        "    else:\n",
        "        print(\" -> Body 'fly_zone' already exists. Skipping.\")\n",
        "\n",
        "    # --- Action 2: Check for and add the touch_sensor ---\n",
        "    if sensor_node.find(\"./touch[@name='touch_sensor']\") is None:\n",
        "        print(\" -> Sensor 'touch_sensor' not found. Adding it...\")\n",
        "        touch_attributes = {'name': 'touch_sensor', 'site': 'fly_sensor'}\n",
        "        ET.SubElement(sensor_node, 'touch', attrib=touch_attributes)\n",
        "        changes_made = True\n",
        "    else:\n",
        "        print(\" -> Sensor 'touch_sensor' already exists. Skipping.\")\n",
        "\n",
        "    # 4. Write to the file ONLY if changes were made\n",
        "    if changes_made:\n",
        "        ET.indent(tree, space=\"  \", level=0)\n",
        "        tree.write(filename, encoding='utf-8', xml_declaration=True)\n",
        "        print(f\"\\n✅ Successfully applied updates to '{filename}'.\")\n",
        "    else:\n",
        "        print(f\"\\n✅ No updates needed. All elements already exist in '{filename}'.\")\n",
        "\n",
        "else:\n",
        "    # This block runs if one or both parent nodes are missing\n",
        "    print(\"❌ Error: Could not find both <worldbody> and <sensor> nodes. No changes were made.\")\n",
        "    if worldbody_node is None:\n",
        "        print(\" -> Missing <worldbody> node.\")\n",
        "    if sensor_node is None:\n",
        "        print(\" -> Missing <sensor> node.\")"
      ],
      "metadata": {
        "id": "aJ60GmH4-P0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def modified_tanh_new(x):\n",
        "    \"\"\"\n",
        "    Calculates the updated modified tanh function.\n",
        "    \"\"\"\n",
        "    k = 3.404\n",
        "    x0 = 0.825\n",
        "    return 0.5 * (1 - np.tanh(k * (x - x0)))"
      ],
      "metadata": {
        "id": "OsHxZveW6yVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import mujoco\n",
        "import xml.etree.ElementTree as ET\n",
        "from gymnasium.spaces import Box\n",
        "\n",
        "# Import the path to the CF2 model from the library\n",
        "from robot_descriptions.cf2_mj_description import MJCF_PATH as CF2_PATH\n",
        "\n",
        "class DroneHoverEnv(MujocoEnv):\n",
        "    \"\"\"\n",
        "    Custom Gymnasium environment for the drone hovering task.\n",
        "    This version loads the drone model from `robot_descriptions`\n",
        "    and programmatically builds the training scene.\n",
        "    \"\"\"\n",
        "\n",
        "    metadata = {\n",
        "    \"render_modes\": [\n",
        "        \"human\",\n",
        "        \"rgb_array\",\n",
        "        \"depth_array\",\n",
        "    ],\n",
        "        \"render_fps\": 100,\n",
        "    }\n",
        "\n",
        "    def __init__(self, episode_len=1_000, frame_skip=5, **kwargs):\n",
        "        utils.EzPickle.__init__(self, **kwargs)\n",
        "\n",
        "        self.model_path = os.path.join(cf2_mj_description.PACKAGE_PATH, \"scene.xml\")\n",
        "        self.total_reward = 0\n",
        "\n",
        "        # --- 3. Define Spaces and Target (same as before) ---\n",
        "        self.action_space = Box(\n",
        "            low=np.array([0.0, -1.0, -1.0, -1.0]),\n",
        "            high=np.array([0.35, 1.0, 1.0, 1.0]),\n",
        "            dtype=np.float64\n",
        "        )\n",
        "\n",
        "        self.observation_space = Box(\n",
        "            low=-np.inf, high=np.inf, shape=(16,), dtype=np.float64\n",
        "        )\n",
        "\n",
        "        # change shape of observation to your observation space size\n",
        "        # load your MJCF model with env and choose frames count between actions\n",
        "        MujocoEnv.__init__(\n",
        "            self,\n",
        "            self.model_path,\n",
        "            frame_skip=5,\n",
        "            observation_space=self.observation_space,\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "        self.episode_len = episode_len\n",
        "        self.frame_skip = frame_skip\n",
        "        self.target_pos = np.array([0.0, 0.0, 0.5])\n",
        "        self.drone_body_id = self.model.body('cf2').id\n",
        "        self.gyro_sensor_id = self.model.sensor('body_gyro').id\n",
        "        self.fly_sensor_id = self.model.sensor('touch_sensor').id\n",
        "\n",
        "\n",
        "    def _get_obs(self):\n",
        "        \"\"\"Constructs the observation vector from the simulation data.\"\"\"\n",
        "        drone_pos = self.data.qpos[:3]\n",
        "        drone_quat = self.data.qpos[3:7]\n",
        "        drone_lin_vel = self.data.qvel[:3]\n",
        "        drone_ang_vel = self.data.sensor(self.gyro_sensor_id).data\n",
        "        vec_to_target = self.target_pos - drone_pos\n",
        "\n",
        "        return np.concatenate([\n",
        "            drone_pos, drone_quat, vec_to_target,\n",
        "            drone_lin_vel, drone_ang_vel\n",
        "        ]).astype(np.float64)\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Applies an action, steps the simulation, and calculates the reward.\"\"\"\n",
        "        self.data.ctrl[:] = action\n",
        "        for _ in range(self.frame_skip):\n",
        "            mujoco.mj_step(self.model, self.data)\n",
        "\n",
        "        drone_pos = self.data.qpos[:3]\n",
        "        distance_to_target = np.linalg.norm(drone_pos - self.target_pos)\n",
        "        reward = distance_to_target\n",
        "\n",
        "        reward = -distance_to_target\n",
        "        reward -= 0.01 * np.square(action).sum()\n",
        "\n",
        "        # Check for contact with the 'touch_sensor' site\n",
        "\n",
        "        # Read the sensor value\n",
        "        touch_reported = False\n",
        "        # print(self.data.sensor(self.fly_sensor_id).data)\n",
        "        sensor_reading = self.data.sensor(self.fly_sensor_id).data[0]\n",
        "\n",
        "        # A positive value means the sensor is being touched\n",
        "        if (sensor_reading > 0 and not touch_reported) or distance_to_target < 0.1:\n",
        "            # print(f\"Drone touched the sensor! | Senor Force {sensor_reading:.3f} | Distance: {distance_to_target:.3f}\")\n",
        "            touch_reported = True\n",
        "            reward = 1.0 # Add a positive reward for touching the sensor\n",
        "\n",
        "        terminated = False\n",
        "        truncated = bool(distance_to_target > 2.0 or drone_pos[2] < 0.05) or (self.step_number > self.episode_len)\n",
        "\n",
        "        observation = self._get_obs()\n",
        "\n",
        "        info = {'distance_to_target': distance_to_target,\n",
        "                \"touch_reported\": touch_reported,\n",
        "                \"sensor_reading\": sensor_reading}\n",
        "        # if(touch_reported):\n",
        "        #     print(info)\n",
        "\n",
        "        return observation, reward, terminated, truncated, info\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        \"\"\"Resets the environment to an initial state.\"\"\"\n",
        "        super().reset(seed=seed)\n",
        "        mujoco.mj_resetData(self.model, self.data)\n",
        "        noise = self.np_random.uniform(low=-0.1, high=0.1, size=3)\n",
        "        self.data.qpos[:3] += noise\n",
        "\n",
        "        return self._get_obs(), {}\n",
        "\n",
        "    # define what should happen when the model is reset (at the beginning of each episode)\n",
        "    def reset_model(self, seed=None):\n",
        "        self.step_number = 0\n",
        "        self.total_reward = 0\n",
        "\n",
        "        # for example, noise is added to positions and velocities\n",
        "        qpos = self.init_qpos + self.np_random.uniform(\n",
        "            size=self.model.nq, low=-0.01, high=0.01\n",
        "        )\n",
        "        qvel = self.init_qvel + self.np_random.uniform(\n",
        "            size=self.model.nv, low=-0.01, high=0.01\n",
        "        )\n",
        "        self.set_state(qpos, qvel)\n",
        "        return self._get_obs()"
      ],
      "metadata": {
        "id": "KjA_zz98FkwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = DroneHoverEnv()\n",
        "print(\"Observation Space Size: \", env.observation_space.shape)\n",
        "print('Actions Space: ', env.action_space)\n",
        "env.close()"
      ],
      "metadata": {
        "id": "NHi9XWqQLl3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_env():\n",
        "  env = DroneHoverEnv(episode_len=hyperparams[\"episode_length\"], render_mode=\"rgb_array\")\n",
        "  check_env(env)\n",
        "  return env"
      ],
      "metadata": {
        "id": "oYantNU3_7k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Training environment\n",
        "env = make_vec_env(make_env,\n",
        "                   n_envs=hyperparams[\"n_envs\"],\n",
        "                   monitor_dir=os.path.join(log_dir, \"monitor\"))\n",
        "\n",
        "normalized_env = VecNormalize(env, norm_obs=True, norm_reward=True)\n",
        "\n",
        "\n",
        "# Create Evaluation environment\n",
        "env_val = make_vec_env(make_env, n_envs=1)\n",
        "normalized_env_val = VecNormalize(env_val, norm_obs=True, norm_reward=True)\n",
        "\n",
        "\n",
        "eval_callback = EvalCallback(normalized_env_val,\n",
        "                             best_model_save_path=log_dir,\n",
        "                             log_path=log_dir,\n",
        "                             render=False,\n",
        "                             deterministic=True,\n",
        "                             n_eval_episodes=20,\n",
        "                             eval_freq=hyperparams[\"eval_freq\"])\n",
        "\n",
        "video_record_callback = VideoRecordCallback(\n",
        "    save_path=os.path.join(log_dir, \"videos\"),\n",
        "    video_length=10_000,\n",
        "    save_freq=hyperparams[\"eval_freq\"],\n",
        "    name_prefix=name_prefix)\n",
        "\n",
        "# Create the callback list\n",
        "callbackList = CallbackList([video_record_callback,\n",
        "                             eval_callback])\n",
        "\n",
        "# learning with tensorboard logging and saving model\n",
        "model = SAC(\"MlpPolicy\",\n",
        "            normalized_env,\n",
        "            verbose=0,\n",
        "            tensorboard_log=os.path.join(log_dir, \"tensorboard\"))\n",
        "\n",
        "model.learn(total_timesteps=hyperparams[\"total_timesteps\"],\n",
        "            callback=callbackList,\n",
        "            progress_bar=False)\n",
        "\n",
        "# Save the model\n",
        "model.save(os.path.join(log_dir, \"final_model\"))\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(model, normalized_env)\n",
        "print(f\"Mean reward: {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
        "\n",
        "env.close()\n",
        "env_val.close()\n",
        "normalized_env.close()\n",
        "normalized_env_val.close()"
      ],
      "metadata": {
        "id": "frDeW5sE_5IR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kin6gNR124yt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}